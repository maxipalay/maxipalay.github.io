<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
	<script type="text/javascript"
			src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
	</script>

	<title>Max's Portfolio</title>
	<link rel="icon" type="image/png" href="/public/images/logo_icon_black_small.png">

	<link rel="stylesheet" href="/public/stylesheets/style.css">

	<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>

</head>


<body class="bg-fixed bg-no-repeat bg-[center_-180px_top] bg-center bg-cover bg-blend-multiply bg-slate-700 h-screen"
  style="background-image: url('/public/images/jumbotron-bg.jpg')">
  
  <script type="text/javascript">
    (function (window, document, dataLayerName, id) {
      window[dataLayerName] = window[dataLayerName] || [], window[dataLayerName].push({ start: (new Date).getTime(), event: "stg.start" }); var scripts = document.getElementsByTagName('script')[0], tags = document.createElement('script');
      function stgCreateCookie(a, b, c) { var d = ""; if (c) { var e = new Date; e.setTime(e.getTime() + 24 * c * 60 * 60 * 1e3), d = "; expires=" + e.toUTCString(); f = "; SameSite=Strict" } document.cookie = a + "=" + b + d + f + "; path=/" }
      var isStgDebug = (window.location.href.match("stg_debug") || document.cookie.match("stg_debug")) && !window.location.href.match("stg_disable_debug"); stgCreateCookie("stg_debug", isStgDebug ? 1 : "", isStgDebug ? 14 : -1);
      var qP = []; dataLayerName !== "dataLayer" && qP.push("data_layer_name=" + dataLayerName), isStgDebug && qP.push("stg_debug"); var qPString = qP.length > 0 ? ("?" + qP.join("&")) : "";
      tags.async = !0, tags.src = "https://maxpalay.containers.piwik.pro/" + id + ".js" + qPString, scripts.parentNode.insertBefore(tags, scripts);
      !function (a, n, i) { a[n] = a[n] || {}; for (var c = 0; c < i.length; c++)!function (i) { a[n][i] = a[n][i] || {}, a[n][i].api = a[n][i].api || function () { var a = [].slice.call(arguments, 0); "string" == typeof a[0] && window[dataLayerName].push({ event: n + "." + i + ":" + a[0], parameters: [].slice.call(arguments, 1) }) } }(i[c]) }(window, "ppms", ["tm", "cm"]);
    })(window, document, 'dataLayer', '09cea3cf-ceae-4c5f-b845-21cfd41901d3');
  </script>
  
  <div id="wrapper">

    <script>
    // JavaScript to handle scrolling color change
    window.addEventListener('scroll', function() {
      var navbar = document.getElementById('navbar');
      var logo = document.getElementById('logo');
      var navitems = document.getElementById('navbar-items')
      var scrolled = window.scrollY > 50;
      var gh_logo = document.getElementById('gh-logo');

      // Adjust the background color based on the scroll position
      if (scrolled) {
        navbar.classList.add('bg-[#f9f9f9]/[1.0]');
        navbar.classList.remove('bg-[#f9f9f9]/[.1]');
        logo.classList.toggle('default-logo', !scrolled);
        logo.classList.toggle('scrolled-logo', scrolled);
        navitems.classList.toggle('text-white', !scrolled);
        navitems.classList.toggle('text-black', scrolled);
        gh_logo.classList.toggle('default-gh-logo', !scrolled);
        gh_logo.classList.toggle('scrolled-gh-logo', scrolled);
      } else {
        navbar.classList.remove('bg-[#f9f9f9]/[1.0]');
        navbar.classList.add('bg-[#f9f9f9]/[.1]');
        logo.classList.toggle('default-logo', !scrolled);
        logo.classList.toggle('scrolled-logo', scrolled);
        navitems.classList.toggle('text-white', !scrolled);
        navitems.classList.toggle('text-black', scrolled);
        gh_logo.classList.toggle('default-gh-logo', !scrolled);
        gh_logo.classList.toggle('scrolled-gh-logo', scrolled);
      }
    });
</script>

<nav id="navbar" class="bg-[#f9f9f9]/[.1] fixed w-full z-20 top-0 start-0 transition ease-in-out duration-200">
    <div class="max-w-screen-xl flex flex-nowrap items-center justify-between mx-auto p-4 px-10">
        <a id="logo" href="/" class="flex items-center space-x-3 rtl:space-x-reverse h-8 w-3/12 min-w-32 bg-no-repeat bg-contain bg-center default-logo"></a>
        <div class="w-full block w-auto justify-end flex" id="navbar-default">
          <ul id="navbar-items" class="text-white text-xs md:text-sm font-medium subpixel-antialiased flex p-0 mt-0 flex-row md:space-x-8 space-x-2 rtl:space-x-reverse border-0">
            <li>
              <a href="/" class="block bg-blue-700 rounded bg-transparent p-0 dark:hover:text-blue-500">Home</a>
            </li>
            <li>
              <a href="/about/" class="block rounded hover:bg-gray-100 hover:bg-transparent border-0 hover:text-blue-700 p-0 dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white dark:hover:bg-transparent">About</a>
            </li>
            <li>
              <a href="https://www.linkedin.com/in/max-palay/" target="_blank" class="block rounded hover:bg-gray-100 hover:bg-transparent border-0 hover:text-blue-700 p-0 dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white dark:hover:bg-transparent">Contact</a>
            </li>
            <li>
              <a id="gh-logo" href="https://github.com/maxipalay" target="_blank" class="block rounded border-0 p-0 h-full w-12 bg-no-repeat bg-contain bg-center default-gh-logo">
              </a>
            </li>
          </ul>
        </div>
      </div>
  </nav>

    <main class="project backdrop-filter backdrop-blur-md bg-opacity-80 bg-slate-800 min-h-screen" >
	<section id="project-content">
        <div class="py-20 w-9/12 md:w-8/12 mx-auto text-white text-justify text-sm md:text-lg font-normal max-w-screen-xl">
            
            <h2 id="project-date" class="text-right text-sm md:text-md font-normal my-4">February, 2024</h2>
            <h1 class="tracking-tight text-center leading-none relative mb-6 mt-0 text-2xl font-semibold text-slate-50 md:text-3xl lg:text-5xl px-16 lg:px-48">
                <span class="relative z-10">Extended Kalman Filter SLAM</span>
            </h1>
            <h1 class="tracking-tight text-center text-sm md:text-lg">
                <span class="relative z-10">Implementation of kinematics, odometry, simulation and EKF for SLAM from scratch.</span>
            </h1>
            <div class="h-0.5 w-1/2 my-8 content-center mx-auto relative">
                <div class="absolute inset-0 bg-gradient-to-r from-black/0 via-white/100 to-black/0 rounded-full"></div>
            </div>

            <div class="flex flex-wrap gap-2 font-mono text-white text-sm font-bold rounded-lg justify-center mx-auto">
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">slam</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">ros2</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">c++</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">rviz2</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">turtlebot</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">lidar</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">extended kalman filter</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">probability</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">git</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">simulation</div>
                
              </div>
            
            <h2 id="overview">Overview</h2>
<div class="w-11/12 mx-auto">
Implementation of an Extended Kalman Filter for Simultaneous Localization and Mapping in ROS2 and C++ from scratch. This project was carried out in the span of 10 weeks.

<br />


<iframe src="https://www.youtube-nocookie.com/embed/ja8nJHA0zF8?si=_LcwnB2mptbbfi2c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" class="mx-auto my-8 center w-full rounded-lg max-w-4xl" style="aspect-ratio: 16 / 9;"></iframe>
<br />
This video shows the implementation working in real life. The visualization shows 2 robots, a blue turtlebot which represents the odometry estimation and the green one which is the estimation based on the EKF. The path corresponding to each robot is also shown. Landmarks are represented by cylinders. The green landmarks are part of the EKF estimation. These are extracted from the LiDAR scans, which are shown in red. There's some latency due to data transmission over a wireless network.
<br />
<br />
</div>

<div class="text-center font-medium">This project's source code is available on <a href="https://github.com/maxipalay/ekf-slam" target="_blank"> <img class="h-8 inline-block relative top-[-2px]" src="../public/logos/github-long.png" /></a></div>

<p><br />
<br /></p>

<h1 id="kinematics--control">Kinematics &amp; Control</h1>

<p>A C++ library was implemented with helper functions for planar body motion, including transforms and geometric operations. A <code class="language-plaintext highlighter-rouge">DiffDrive</code> class implements the forward kinematics and odometry for a differential drive robot.</p>

<h1 id="the-extended-kalman-filter">The Extended Kalman Filter</h1>

<p>The Extended Kalman Filter allows us to get an estimation of the environment (robot + landmarks locations). Our system is nonlinear, so by using the EKF we linearize the state transition model and propagate uncertainty using the linearization as well.
<br />
<br />
Briefly, the steps are:</p>
<div class="w-11/12 mx-auto">
<li>Update the estimate using the motion model</li>
<li>Propagate the uncertainty using linearized state transition model</li>
<li>Perform an update to our estimate by using measurements. This is where the LiDAR sensor and landmark detection are used. Using each measurement, we refine the state.</li>
</div>

<h1 id="landmark-detection">Landmark detection</h1>

<p><img src="../public/images/projects/ekf-slam/circle_fitting.png" class="mx-auto my-8 center w-2/3 rounded-lg max-w-4xl" /></p>

<p>The landmark detection pipeline consists of multi-step processing of the raw lidar data.</p>

<div class="mx-auto">
<ul class="pl-8 md:pl-12 list-decimal">
    <li>Clustering the lidar scan points</li>
    <li>Filtering the clusters (by # of points in the cluster)</li>
    <li>Classifying each cluster as circle/not circle.</li>
    <li>Fitting circles to the clusters that made it through.</li>
    <li>Filtering the results based on our assumptions on the environment and landmarks. E.g. allowable radius of landmark.</li>
  </ul>
</div>

<h1 id="simulation">Simulation</h1>

<iframe src="https://www.youtube-nocookie.com/embed/vc0cHPwj2pw?si=TI10ZDo4-zkX81_B" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" class="mx-auto my-8 center w-full rounded-lg max-w-4xl" style="aspect-ratio: 16 / 9;"></iframe>
<p><br />
This video shows the implementation in simulation. The visualization shows 3 robots, a blue turtlebot which represents the odometry estimation, a red one which is the ground truth in the implemented simulation, and the green one which is the estimation based on the EKF. The path corresponding to each robot is also shown.
<br /></p>

<p>A full simulation environment was implemented as a ROS2 node. The simulation performs the forward kinematics based on velocity commands, and moves the robot accordingly. Noise &amp; wheel slip are introduced sampling from Gaussian distributions for a more realistic environment. The environment provides configurable landmarks (cylinders) and walls. A simulated lidar sensor generates measurements based on the robot’s location in the environment, just like its real counterpart.
<br />
<br />
A list of features of the simulation environment follows:</p>

<div class="w-11/12 mx-auto">
<li><span class="font-semibold">Landmarks &amp; walls</span>: the environment is enclosed in 4 simulated walls. Configurable cylindrical landmarks allow the user to test the performance on different scenarios.</li>
<li><span class="font-semibold">Simulated LiDAR measurements</span>: the EKF relies on measurements extensively. Having implemented the simulated measurements, it is possible to fully develop and test the EKF in simulation. The generated measurements include Gaussian noise.</li>
<li><span class="font-semibold">Collisions</span>: the robot can collide with landmarks, the wheels will slip and the robot will glide tangential to the landmark it collided with. This is helpful for creating a large difference between the odometry estimate and the real robot location. Also, real robots do crash!</li>
<li><span class="font-semibold">Noise &amp; wheel slip</span>: Besides noise on the simulated LiDAR, real wheels on the real world slip, motors do not respond ideally, so adding random wheel slip makes the environment more realistic.</li>
</div>

<h1 id="real-world-test">Real world test</h1>

<p>The simulation can only get us so far, especially if we don’t have accurate models of our sensor noise, slip, and motor responses. Getting the filter working on the real robot required a lot of tuning, especially the noise parameters in the EKF and parameters in the landmark association.
<br />
<br />
This post’s main video shows the algorithm working on a real Turtlebot 3 burger. The video shows the data being fed back to a PC and shown in Rviz2. The robot is driven around a course, and back to its initial position. The wheel odometry is pretty far from the actual position, while the SLAM estimation provides a better idea of where the robot is. The course is pretty simple, and carton walls were added due to the cluttered environment that produced many landmarks (which can be as bad as good!).</p>

<h1 id="qualitative-results">Qualitative Results</h1>

<p>Driving the robot around the course and taking it back to its initial pose (eye-measuring using a mark on the floor, shown in the main video).
<br />
<br />
Final SLAM estimation <code class="language-plaintext highlighter-rouge">(x,y,theta): (-0.02, 0.01, -0.06)</code>
<br />
Final odometry estimation <code class="language-plaintext highlighter-rouge">(x,y,theta): (0.02, 0.24, -0.67)</code></p>

        </div>
		

	</section>

</main>


    

<footer class="rounded-lg shadow bg-[#f9f9f9]/[1.0]">
    <div class="w-full max-w-screen-xl mx-auto p-4">
        <div class="sm:flex sm:items-center sm:justify-between">
            <a class="flex items-center mb-4 sm:mb-0 space-x-3 rtl:space-x-reverse">
                <img src="/public/images/logo_acronym_small_black.png" class="h-6" alt="Logo" />
            </a>
            <ul class="flex flex-wrap items-center mb-6 text-sm font-medium text-gray-500 sm:mb-0 dark:text-gray-400">
                <li>
                    <a href="/about/" class="hover:underline me-4 md:me-6">About</a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/maximiliano-palay/" target="_blank" class="hover:underline">Contact</a>
                </li>
            </ul>
        </div>
        <hr class="my-6 border-gray-200 sm:mx-auto dark:border-gray-700 lg:my-4" />
        <span class="block text-sm text-gray-500 sm:text-center dark:text-gray-400">2024 - Maximiliano Palay</span>
    </div>
</footer>




  </div>

  <script>
    document.getElementById('hide-popup').addEventListener('click', function () {
      var popup = document.getElementById('popup');
      popup.classList.toggle('hidden');
    });
  </script>

</body>

</html>