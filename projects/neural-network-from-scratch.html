<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
	<script type="text/javascript"
			src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
	</script>

	<title>Max's Portfolio</title>
	<link rel="icon" type="image/png" href="/public/images/logo_icon_black_small.png">

	<link rel="stylesheet" href="/public/stylesheets/style.css">

	<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>

</head>


<body class="bg-fixed bg-no-repeat bg-[center_-180px_top] bg-center bg-cover bg-blend-multiply bg-slate-700 h-dvh h-screen"
  style="background-image: url('/public/images/jumbotron-bg.jpg')">
  
  <script type="text/javascript">
    (function (window, document, dataLayerName, id) {
      window[dataLayerName] = window[dataLayerName] || [], window[dataLayerName].push({ start: (new Date).getTime(), event: "stg.start" }); var scripts = document.getElementsByTagName('script')[0], tags = document.createElement('script');
      function stgCreateCookie(a, b, c) { var d = ""; if (c) { var e = new Date; e.setTime(e.getTime() + 24 * c * 60 * 60 * 1e3), d = "; expires=" + e.toUTCString(); f = "; SameSite=Strict" } document.cookie = a + "=" + b + d + f + "; path=/" }
      var isStgDebug = (window.location.href.match("stg_debug") || document.cookie.match("stg_debug")) && !window.location.href.match("stg_disable_debug"); stgCreateCookie("stg_debug", isStgDebug ? 1 : "", isStgDebug ? 14 : -1);
      var qP = []; dataLayerName !== "dataLayer" && qP.push("data_layer_name=" + dataLayerName), isStgDebug && qP.push("stg_debug"); var qPString = qP.length > 0 ? ("?" + qP.join("&")) : "";
      tags.async = !0, tags.src = "https://maxpalay.containers.piwik.pro/" + id + ".js" + qPString, scripts.parentNode.insertBefore(tags, scripts);
      !function (a, n, i) { a[n] = a[n] || {}; for (var c = 0; c < i.length; c++)!function (i) { a[n][i] = a[n][i] || {}, a[n][i].api = a[n][i].api || function () { var a = [].slice.call(arguments, 0); "string" == typeof a[0] && window[dataLayerName].push({ event: n + "." + i + ":" + a[0], parameters: [].slice.call(arguments, 1) }) } }(i[c]) }(window, "ppms", ["tm", "cm"]);
    })(window, document, 'dataLayer', '09cea3cf-ceae-4c5f-b845-21cfd41901d3');
  </script>
  
  <div id="wrapper">

    <script>
    // JavaScript to handle scrolling color change
    window.addEventListener('scroll', function() {
      var navbar = document.getElementById('navbar');
      var logo = document.getElementById('logo');
      var navitems = document.getElementById('navbar-items')
      var scrolled = window.scrollY > 50;
      var gh_logo = document.getElementById('gh-logo');

      // Adjust the background color based on the scroll position
      if (scrolled) {
        navbar.classList.add('bg-[#f9f9f9]/[1.0]');
        navbar.classList.remove('bg-[#f9f9f9]/[.1]');
        logo.classList.toggle('default-logo', !scrolled);
        logo.classList.toggle('scrolled-logo', scrolled);
        navitems.classList.toggle('text-white', !scrolled);
        navitems.classList.toggle('text-black', scrolled);
        gh_logo.classList.toggle('default-gh-logo', !scrolled);
        gh_logo.classList.toggle('scrolled-gh-logo', scrolled);
      } else {
        navbar.classList.remove('bg-[#f9f9f9]/[1.0]');
        navbar.classList.add('bg-[#f9f9f9]/[.1]');
        logo.classList.toggle('default-logo', !scrolled);
        logo.classList.toggle('scrolled-logo', scrolled);
        navitems.classList.toggle('text-white', !scrolled);
        navitems.classList.toggle('text-black', scrolled);
        gh_logo.classList.toggle('default-gh-logo', !scrolled);
        gh_logo.classList.toggle('scrolled-gh-logo', scrolled);
      }
    });
</script>

<nav id="navbar" class="bg-[#f9f9f9]/[.1] fixed w-full z-20 top-0 start-0 transition ease-in-out duration-200">
    <div class="max-w-screen-xl flex flex-nowrap items-center justify-between mx-auto p-4 px-10">
        <a id="logo" href="/" class="flex items-center space-x-3 rtl:space-x-reverse h-8 w-3/12 min-w-32 bg-no-repeat bg-contain bg-center default-logo"></a>
        <div class="w-full block w-auto justify-end flex" id="navbar-default">
          <ul id="navbar-items" class="text-white text-xs md:text-sm font-medium subpixel-antialiased flex p-0 mt-0 flex-row md:space-x-8 space-x-2 rtl:space-x-reverse border-0">
            <li>
              <a href="/" class="block bg-blue-700 rounded bg-transparent p-0 dark:hover:text-blue-500">Home</a>
            </li>
            <li>
              <a href="/about/" class="block rounded hover:bg-gray-100 hover:bg-transparent border-0 hover:text-blue-700 p-0 dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white dark:hover:bg-transparent">About</a>
            </li>
            <li>
              <a href="https://www.linkedin.com/in/max-palay/" target="_blank" class="block rounded hover:bg-gray-100 hover:bg-transparent border-0 hover:text-blue-700 p-0 dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white dark:hover:bg-transparent">Contact</a>
            </li>
            <li>
              <a id="gh-logo" href="https://github.com/maxipalay" target="_blank" class="block rounded border-0 p-0 h-full w-12 bg-no-repeat bg-contain bg-center default-gh-logo">
              </a>
            </li>
          </ul>
        </div>
      </div>
  </nav>

    <main class="project backdrop-filter backdrop-blur-md bg-opacity-80 bg-slate-800 min-h-screen" >
	<section id="project-content">
        <div class="py-20 w-9/12 md:w-8/12 mx-auto text-white text-justify text-sm md:text-lg font-normal max-w-screen-xl">
            
            <h2 id="project-date" class="text-right text-sm md:text-md font-normal my-4">October, 2023</h2>
            <h1 class="tracking-tight text-center leading-none relative mb-6 mt-0 text-2xl font-semibold text-slate-50 md:text-3xl lg:text-5xl px-16 lg:px-48">
                <span class="relative z-10">Neural Network from scratch</span>
            </h1>
            <h1 class="tracking-tight text-center text-sm md:text-lg">
                <span class="relative z-10"></span>
            </h1>
            <div class="h-0.5 w-1/2 my-8 content-center mx-auto relative">
                <div class="absolute inset-0 bg-gradient-to-r from-black/0 via-white/100 to-black/0 rounded-full"></div>
            </div>

            <div class="flex flex-wrap gap-2 font-mono text-white text-sm font-bold rounded-lg justify-center mx-auto">
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">machine learning</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">ai</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">fully connected</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">neural network</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">python</div>
                
                <div class="px-2 py-1 rounded-lg flex items-center justify-center bg-blend-multiply bg-slate-500">numpy</div>
                
              </div>
            
            <h3 id="overview">Overview</h3>

<p>Created a fully connected neural network form scratch in python using numpy. Hyperparameters are fully configurable by the user, who can set the number of layers and number of neurons per layer, number of inputs and outputs, and more.
<br />
<br /></p>
<div class="text-center font-medium">This project's source code is available on <a href="https://github.com/maxipalay/fully-connected-neural-net" target="_blank"> <img class="h-8 inline-block relative top-[-2px]" src="../public/logos/github-long.png" /></a></div>

<h2 id="neural-networks">Neural Networks</h2>

<p>In this project a subset of neural networks is implemented -feed forward, fully connected networks- using
perceptrons as the units for computation and learning. The perceptron is a unit which takes n inputs, performs a
linear combination of them, this result is then fed through an activation function, and at the end gives a single output.
A representation of a perceptron is presented in Image 1.</p>

<p><img src="../public/images/projects/neural-network-from-scratch/neuron.png" class="mx-auto my-8 center w-1/3 rounded-lg max-w-4xl" /></p>
<div class="italic text-center font-xs">Image 1: Graphical representation of a Perceptron.</div>
<p><br /></p>

<p>The linear combination is done using weights, which are learnable parameters of the perceptron, and a bias -which
is also a learnable parameter- is added to the result. The bias can either be seen as a weight multiplying a fixed input
of 1, or as a number added to the linear combination. The ‚Äúlearning‚Äù on a perceptron involves adjusting the set of
weights and biases to minimize the error between the output of the perceptron and a target output for a set of given
inputs.
<br />
<br />
The role of the activation function is to add nonlinearity to the behavior of the perceptron. Functions such as
sigmoid, rectified linear units (ReLU), or hyperbolic tangent are widely used as activations for perceptrons.
While a single perceptron is capable of learning simple problems, a combination of multiple perceptrons is needed
to allow for learning complex nonlinear functions. Perceptrons can be stacked vertically (one layer with multiple
perceptrons) and horizontally (multiple layers, where the output of the previous layer is fed as input to the next
layer), to form networks with varying architectures. A visual representation of a multilayer network as the one
mentioned is shown in Image 2.</p>

<p><img src="../public/images/projects/neural-network-from-scratch/network.png" class="mx-auto my-8 center w-1/3 rounded-lg max-w-4xl" /></p>
<div class="italic text-center font-xs">Image 2: Feedforward multi-layer neural network.</div>
<p><br /></p>

<p>The network depicted above consists of fully connected layers, meaning that each output of a layer is fed to every
input of the next layer. Each big circle is a full perceptron as previously explained. This is the variation of neural
networks considered for the scope of this homework. The first layer is usually referred to as an input layer and
consists of the inputs being fed into the network. Subsequent layers are called hidden layers, except for the last one,
which is referred to as the output layer. In this case, the network has n inputs and a single output, but this is
configurable to accommodate any combination of m inputs and n outputs.</p>

<h2 id="gradient-descent--backpropagation">Gradient Descent &amp; Backpropagation</h2>

<p>The basis for minimizing the error -or fitting the network- is gradient descent. The network begins training with an
arbitrary state, and gradient descent is the search algorithm that allows finding a set of weights that minimizes the
error by iteratively updating the set of weights a small amount according to the gradient of the error surface.
One variant of gradient descent is stochastic gradient descent, where instead of calculating the error for all training
examples and then updating the weights, the error is calculated, and weights are updated for each sample.
<br />
<br />
Gradient descent provides a direct way of optimizing the weights for a layer. But in the case of multilayer networks,
we need a way to propagate the update of weights to all layers. Backpropagation is an algorithm that provides a
way of updating all weights in a network while using gradient descent to optimize. The goal of backpropagation is
to minimize the error between the target values and the actual outputs.</p>

<h2 id="implementation">Implementation</h2>

<p>The implementation was performed using object-oriented programming in python. A class named <code class="language-plaintext highlighter-rouge">FCLayer</code>
represents a fully connected layer, including its weights and biases, the activation function and the derivative of the
activation function which is used for backpropagation. A class <code class="language-plaintext highlighter-rouge">NN</code> represents the neural network and stores a list of
layers. It provides methods for training the network using backpropagation and performing inference.
<br /></p>

<p>A summary of parameters that are relevant for training:</p>
<div class="w-11/12 mx-auto">
<li>Network architecture: number of layers, neurons per layer</li>
<li>Batch size</li>
<li>Number of epochs: number of times the network updates on the whole set of training data</li>
<li>Error threshold: threshold to stop training</li>
<li>Learning rate</li>
<li>Momentum</li>
</div>

<h2 id="results">Results</h2>

<p>The implemented network is tested with the goal of learning a noisy sine function. This single-input-single-output problem is on the simple end of functions that a neural network can
learn, but it is a good check to see if the network learns. It was extensively used while developing the algorithm for
fast, simple checks.
<br />
<br />
<img src="../public/images/projects/neural-network-from-scratch/results.png" class="mx-auto my-8 center w-2/3 rounded-lg max-w-4xl" /></p>
<div class="italic text-center font-xs">Image 3: Plots for test of model learning the sine function. The left plot shows the RMSE for both the training set and the validation for each epoch. The rightmost plot shows the ground truth data with added noise (hence the thickness of the plot), and predictions
for both the training set and validation set.</div>
<p><br />
Random values were generated in the range [0,2ùúã], shuffled and passed through a sine function. Gaussian noise
was added to the results of the sine function. The generated values were then normalized to the range [0,1]. A part
(15%) of the generated samples was set aside for validation/evaluation. The model was then trained on the remaining
85% of the generated samples. The evolution of error over training and a plot of predictions on both training and
evaluation sets are shown in Figure 3.
<br />
<br />
In this case, several configurations were tested, and the final one proved to strike a good balance between low
overfit, fast training time and overall low error. The model used consists of three layers, two of 20 neurons, and an
output layer of 1 neuron. The learning rate used was 0.1, momentum was left default at 0.6. Batch size used is 64
samples.</p>


        </div>
		

	</section>

</main>


    

<footer class="rounded-lg shadow bg-[#f9f9f9]/[1.0]">
    <div class="w-full max-w-screen-xl mx-auto p-4">
        <div class="sm:flex sm:items-center sm:justify-between">
            <a class="flex items-center mb-4 sm:mb-0 space-x-3 rtl:space-x-reverse">
                <img src="/public/images/logo_acronym_small_black.png" class="h-6" alt="Logo" />
            </a>
            <ul class="flex flex-wrap items-center mb-6 text-sm font-medium text-gray-500 sm:mb-0 dark:text-gray-400">
                <li>
                    <a href="/about/" class="hover:underline me-4 md:me-6">About</a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/maximiliano-palay/" target="_blank" class="hover:underline">Contact</a>
                </li>
            </ul>
        </div>
        <hr class="my-6 border-gray-200 sm:mx-auto dark:border-gray-700 lg:my-4" />
        <span class="block text-sm text-gray-500 sm:text-center dark:text-gray-400">2024 - Maximiliano Palay</span>
    </div>
</footer>




  </div>

  <div id="popup" class="fixed bottom-0 right-0 z-50 p-2 max-w-xl">
    <div class="relative">
      <div class="relative rounded-lg shadow bg-slate-800">
        <!-- Modal header -->
        <div class="flex items-center justify-between p-2">
          <p class="text-sm text-gray-500 dark:text-gray-400 px-4">
            This site is currently under development. Feedback is welcome!
          </p>
          <button type="button" id="hide-popup"
            class="text-slate-400 rounded-lg text-sm w-6 h-6 ms-auto inline-flex justify-center items-center bg-slate-700 hover:bg-slate-600 hover:text-white">
            <svg class="w-2 h-2" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 14 14">
              <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                d="m1 1 6 6m0 0 6 6M7 7l6-6M7 7l-6 6" />
            </svg>
          </button>
        </div>
      </div>
    </div>
  </div>

  <script>
    document.getElementById('hide-popup').addEventListener('click', function () {
      var popup = document.getElementById('popup');
      popup.classList.toggle('hidden');
    });
  </script>

</body>

</html>